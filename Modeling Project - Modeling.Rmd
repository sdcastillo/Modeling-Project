---
title: "Modeling Project - Data Prep"
author: "Sam Castillo"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    theme: cerulean
    toc: yes
  bibliography: bibliography.bib
csl: biomed-central.csl
email: castillo.sam.d@gmail.com

---

```{r global options, include = FALSE}
knitr::opts_chunk$set( warning=FALSE, message=FALSE)
library(tidyverse)
packages <- c("gbm", "xgboost", "caret", "tidyr", "ggplot2", "lubridate", "corrplot", "caretEnsemble", "e1071", "ggridges", "forcats", "car", "fastDummies", "glmnet", "ggpubr", "xgboost", "broom", "caTools")
purrr::walk(packages, library, character.only = TRUE, warn.conflicts = FALSE)
```

This file will be where I do the model building.

##Training/Test Split

We will split the `train` data into a smaller training set and a validation sets.  What is a good size to split at?  With less training data, there is more variance in the parameter estimates.  If the test set is too small, there will be high variance in the predictions.  If the training set is too small, there will be a lot of variance in the training parameters.  The goal is to divide the data such that there is a good balance the two.

The process will be

1. Split `train` into 80% training and 20% validation
2. Use cross validation to fit models on the train set by tuning hyperparameters
3. Use the 20% validation set to evaluate competing models
4. Retrain the final model on the combined data after fixing hyperparameters
5. Make final predictions based on `test.txt`.

[source](https://www.researchgate.net/post/Is_there_an_ideal_ratio_between_a_training_set_and_validation_set_Which_trade-off_would_you_suggest)

#Preprocessing

Most of the preprocessing has been handled already because there are no missing values and the features are centered at zero and symmetric.

This is the main data used

```{r}
#Remember to subtract 1 from predictions before submitting!!
df <- combined %>% select( -V29, -ID, -spike)

data_for_training <- df %>% filter(source == "train") %>% select(-source, -Amount)
data_for_predictions <- df %>% filter(source == "test") %>% select(-source, -Amount)
train_index <- createDataPartition(data_for_training$log_amount, p = 0.8, list = FALSE) %>% as.numeric()

train <- data_for_training %>% dplyr::slice(train_index) %>% select(log_amount, everything())
test <- data_for_training %>% dplyr::slice(-train_index) %>% select(log_amount,everything())

#some models need a matrix instead of a data frame
train_x <- train %>% select(-log_amount) %>% as.matrix()
train_y <- train$log_amount
holdout_x <- data_for_predictions %>% dplyr::select(-log_amount) %>% as.matrix()

#some models need a matrix instead of a data frame
test_x <- test %>% select(-log_amount) %>% as.matrix()
test_y <- test$log_amount
    
saveRDS(train_x, "train_x.RDS")
saveRDS(train_y, "train_y.RDS")

```



This is the data excluding the spikes

```{r}
df <- combined %>% filter(spike == "none") %>% select( -Amount, -V29, -ID)
data_for_training <- df %>% filter(source == "train") %>% select(-source, -spike)
data_for_predictions <- df %>% filter(source == "test") %>% select(-source, -spike)
train_index <- createDataPartition(data_for_training$log_amount, p = 0.8, list = FALSE) %>% as.numeric()
train_no_spikes <- data_for_training %>% dplyr::slice(train_index) %>% select(log_amount, everything())
test_no_spikes <- data_for_training %>% dplyr::slice(-train_index) %>% select(log_amount, everything())
```



#Modeling

I fit a baseline model before doing any transformations.  This allows me to assess if I'm making improvements reducing the "irreducible" error.

```{r}
eval_model <- function(input_model, input_data = "train") {
  if(input_data == "train"){
    model_prediction <- predict.train(input_model, train_x)
    postResample(pred = model_prediction, obs = train_y)}
  else {
    model_prediction <- predict.train(input_model, test_x)
    postResample(pred = model_prediction, obs = test_y)
  }
}

```

##Baseline

Fit a baseline model with the features which have the highest correlation with `Amount`.

* This performs poorly on predicting high outliers of the target
* Residuals are approximately normal

```{r}
regressControl  <- trainControl(method="repeatedcv",
                    number = 5,
                    repeats = 1, #set this to 1 for now
                    returnResamp = "all"
                    ) 


baseline <- train(log_amount ~ V2 + V7 + V5,
           data = train,
           method  = "lm",
           trControl = regressControl)

plot(baseline$finalModel)
eval_model(baseline)
```

Drop the high-leverage outliers from the training data.

```{r}
train <- train %>% 
  dplyr::slice(-c(14568, 172386, 200929))
```


##GLM with all predictors

From fitting a model with all predictors first we see that `V28` through `V31` do not appear to be significant.

```{r}
regressControl  <- trainControl(method="repeatedcv",
                    number = 10,
                    repeats = 3, #set this to 1 for now
                    returnResamp = "all"
                    ) 


GLM_all <- train(log_amount ~ ., #these have the highest correlations with the Amount
           data = train,
           method  = "lm",
           trControl = regressControl)

tidy(GLM_all$finalModel) %>% select(-statistic) %>% arrange(desc(p.value))
plot(GLM_all$finalModel)
eval_model(GLM_all)
```

Based on the p-values being greater than 0.05, I drop the predictors `V28` through `V31` from the model.

```{r}
regressControl  <- trainControl(method="repeatedcv",
                    number = 10,
                    repeats = 3, #set this to 1 for now
                    returnResamp = "all"
                    ) 


GLM_best <- train(log_amount ~ ., #these have the highest correlations with the Amount
           data = train %>% select(-V28, -V30, -V31, -V33, -V13, -V32) ,
           method  = "lm",
           trControl = regressControl)

tidy(GLM_best$finalModel) %>% select(-statistic) %>% arrange(desc(p.value))
plot(GLM_best$finalModel)
eval_model(GLM_best)

summary(GLM_best)
```



##GLM with all predictors excluding spikes

```{r}
regressControl  <- trainControl(method="repeatedcv",
                    number = 10,
                    repeats = 3, 
                    returnResamp = "all"
                    ) 

GLM_all_no_spike <- train(log_amount ~ ., 
           data = train_no_spikes %>% select(-V28, -V30, -V31, -V33, -V13, -V32),
           method  = "lm",
           trControl = regressControl)

summary(GLM_all_no_spike)
tidy(GLM_all_no_spike$finalModel) %>% select(-statistic) %>% arrange(desc(p.value))
eval_model(GLM_all_no_spike)
```

```{r}
plot(GLM_all_no_spike$finalModel)
```

We look at the residuals vs fitted.

```{r}
test_no_spikes %>% 
  mutate(predictions = predict.train(GLM_all_no_spike, test_no_spikes)) %>% 
  ggplot(aes(log_amount, predictions)) + 
  geom_point() + 
  ggtitle("Predictions vs Target for GLM excluding spikes")
```


##XGBoost

To deal with non-linear relationships, we need a more flexible model.

Here we will spend a little extra time in tuning the parameters of this model.  This is closely following [this kaggle kernal](https://www.kaggle.com/pelkoja/visual-xgboost-tuning-with-caret).

The tuning parameters are

* nrounds: Number of trees, default: 100
* max_depth: Maximum tree depth, default: 6
* eta: Learning rate, default: 0.3
* gamma: Used for tuning of Regularization, default: 0
* colsample_bytree: Column sampling, default: 1
* min_child_weight: Minimum leaf weight, default: 1
* subsample: Row sampling, default: 1

We'll break down the tuning of these into five sections:

* Step 1. Fixing learning rate `eta` and number of iterations `nrounds`
* Step 2. Maximum depth `max_depth` and child weight `min_child_weight`
* Step 3. Setting column `colsample_bytree` and row sampling `subsample`
* Step 4. Experimenting with different `gamma` values
* Step 5. Reducing the learning rate `eta`

As a baseline to the xgboost, we'll first fit using the default parameters.

```{r}
grid_default <- expand.grid(
  nrounds = 100,
  max_depth = 3,
  eta = 0.3,
  gamma = 0,
  colsample_bytree = 1,
  min_child_weight = 1,
  subsample = 1
)

train_control <- caret::trainControl(
  method = "none",
  verboseIter = TRUE, # no training log
  allowParallel = TRUE # FALSE for reproducible results 
)

xgb_base <- caret::train(
  x = train_x,
  y = train_y,
  trControl = train_control,
  tuneGrid = grid_default,
  method = "xgbTree",
  eval_metric = "mae"
)

xgb_base

```

We'll start with the "bigger knobs" to tune and then use these settings to find the best of the "smaller knobs", and then come back and refine these more significant paramters.  We start by fixing the number of trees.  This controls the total number of regression trees to use.  This is selected in combination with the learning rate.  Using a lower learning rate updates the predictions more slowly and so requires a larger number of iterations, or `nrounds` in order to minimize the loss function.  Setting this too high eventually leads to instability.  Using more trees and a lower learning rate is almost always better, but has diminishing returns.  To start, in order to reduce compute time when choosing the other parameters, we set this to 1000.  After the other parameters have been chose, we will come back and turn this up.

```{r}
nrounds <- 500
```

Then we can fill in the other items, using suggestions from (here)[https://www.slideshare.net/OwenZhang2/tips-for-data-science-competitions/14].  


```{r}
# note to start nrounds from 200, as smaller learning rates result in errors so
# big with lower starting points that they'll mess the scales

t1 <-  Sys.time()

tune_grid <- expand.grid(
  nrounds = seq(from = 50, to = 500, by = 100),
  eta = c(0.1, 0.2, 0.4),
  max_depth = 3,
  gamma = 0,
  colsample_bytree = 1,
  min_child_weight = 1,
  subsample = 1
)

tune_control <- caret::trainControl(
  method = "cv", # cross-validation
  number = 3, # with n folds 
  verboseIter = FALSE, # no training log
  allowParallel = TRUE # FALSE for reproducible results 
)

xgb_tune <- caret::train(
  x = train_x,
  y = train_y,
  trControl = tune_control,
  tuneGrid = tune_grid,
  method = "xgbTree",
  verbose = TRUE
)

t2 <- Sys.time()

timediff <- t2 - t1

# helper function for the plots
tuneplot <- function(x, probs = .90) {
  ggplot(x) +
    coord_cartesian(ylim = c(quantile(x$results$RMSE, probs = probs), min(x$results$RMSE))) +
    theme_bw()
}

plot(xgb_tune)
xgb_tune
```

From the plots above, we see that the best learning rate `eta` is at 0.4, which is a high value just to start.  GBMs generally perform better with a larger number of trees, but it takes longer for the model to train.  To make this faster, we'll set the number of trees to 250 while tuning the other parameters.

Next, we move on to finding a good value for the max tree depth.  We start with 3 +/- 1.  The maximum depth controls the depth or "height" of each tree and helps to avoid overfitting.  A higher depth can capture interaction effects better, but setting too high will overfit to the training set.  We also try higher values of `min_child_weight`, which controls the minimum number of observations that are allowed in each end node.  Higher values prevent overfitting.

The code below took 30 minutes to fit.

```{r}
t1 <-  Sys.time()

tune_grid2 <- expand.grid(
  nrounds = c(150, 300, 500),
  eta = xgb_tune$bestTune$eta,
  max_depth = c(2, 3, 4),
  gamma = 0,
  colsample_bytree = 1,
  min_child_weight = c(1, 2, 3),
  subsample = 1
)

xgb_tune2 <- caret::train(
  x = train_x,
  y = train_y,
  trControl = tune_control,
  tuneGrid = tune_grid2,
  method = "xgbTree",
  verbose = TRUE
)

timediff <-  Sys.time() - t1

xgb_tune2$results %>% 
  ggplot(aes(nrounds, RMSE, color = as.factor(max_depth))) + 
  geom_line() + 
  facet_wrap(vars(min_child_weight))

saveRDS(xgb_tune2, "xgb_tune2.RDS")

eval_model(xgb_tune2)
plot(xgb_tune2)
varImp(xgb_tune2)
```


```{r}
xgb_tune2$bestTune
```

We see that the best max depth is 4 with  `min_child_wight` of 2. 


#Model for deductibles

```{r}
#this should really be rewritten as a function!  No time.
df <- combined %>% select(-Amount, -V29, -ID)
data_for_training <- df %>% filter(source == "train") %>% select(-source, -log_amount)
data_for_predictions <- df %>% filter(source == "test") %>% select(-source, -log_amount)
train_index <- createDataPartition(data_for_training$spike, p = 0.8, list = FALSE) %>% as.numeric()

train_spike <- data_for_training %>% dplyr::slice(train_index) %>% dplyr::select(spike, everything())
test_spike <- data_for_training %>% dplyr::slice(-train_index) %>% dplyr::select(spike, everything())

train_x_spike <- train_spike %>% dplyr::select(-spike) %>% as.matrix()
train_y_spike <- train_spike$spike
    
test_x_spike <- test_spike %>% select(-spike) %>% as.matrix()
test_y_spike <- test$spike
```

I can build a model with 97 % accuracy?

```{r}
t1 <-  Sys.time()

spike_grid <- expand.grid(
  nrounds = 100,
  eta = 0.5,
  max_depth = 3,
  gamma = 0,
  colsample_bytree = 1,
  min_child_weight = 1,
  subsample = 1
)

spike_control <- caret::trainControl(
  method = "cv", # cross-validation
  number = 3, # with n folds 
  verboseIter = FALSE, # no training log
  allowParallel = TRUE # FALSE for reproducible results 
)

spike_tune <- caret::train(
  x = train_x,
  y = train_y,
  trControl = spike_control,
  tuneGrid = spike_grid,
  method = "xgbTree",
  verbose = TRUE
)

t2 <- Sys.time()

timediff <- t2 - t1

eval_model(spike_tune, "test")
varImp(spike_tune)
```

```{r}
combined %>% 
  sample_frac(0.01) %>% 
  ggplot(aes(V2, V26, color = spike)) + 
  geom_point()
```

#Making Predictions

#Remember to reverse the log and subtract 1 from log_amount before submitting predictions

```{r}
#write the predictions to a csv file
make_predictions <- function(model, write = F){
  output_path <- paste0("Predictions/",as.character(model$method)," Predictions - ", format(Sys.time(), '%d %B %Y'), ".txt")
  pred <- (exp(predict.train(model, holdout_x)) - 1)
  
  if(write == T){
    data_frame(ID = test_raw$ID, Amount = pred) %>% 
      write_tsv(., path = output_path)
  } else{return(pred)}
  
}

xgb_predictions <- make_predictions(xgb_tune2)
glm_predictions <- make_predictions(GLM_best)

data_frame(xgb = xgb_predictions,
           glm = glm_predictions) %>% 
  ggplot(aes(xgb, glm)) + 
  geom_point() 

#write predictions to file
make_predictions(xgb_tune2, write = T)
```

#Variable Importance

```{r}
varImp(xgb_tune2)
```





